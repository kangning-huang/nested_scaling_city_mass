#!/usr/bin/env python3
"""
03a_submit_batch_exports_nudged.py - Submit GEE batch exports for nudged H3 grids.

This is an extension of 03a_submit_batch_exports.py that works with nudged hexagon
grids generated by 01b_create_h3_grids_nudged.py for sensitivity analysis.

Usage:
    # Submit all nudge directions for resolution 6
    python scripts/03a_submit_batch_exports_nudged.py --resolution 6

    # Submit specific direction only
    python scripts/03a_submit_batch_exports_nudged.py --resolution 6 --direction north

    # Dry run to estimate task count
    python scripts/03a_submit_batch_exports_nudged.py --resolution 6 --dry-run

Author: Generated for NYU China Grant project - Sensitivity Analysis
Date: 2025
"""

import argparse
import json
import sys
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any

import ee
import pandas as pd
import geopandas as gpd
from tqdm import tqdm

sys.path.insert(0, str(Path(__file__).parent))
from utils.paths import get_resolution_dir

# Configuration
BASE_DIR = Path(__file__).resolve().parents[1]
PROCESSED_DIR = BASE_DIR / "data" / "processed"
GEE_PROJECT = 'ee-knhuang'
DRIVE_FOLDER = 'GEE_Batch_Exports_Nudged'

# Default nudge distances (km) per resolution
DEFAULT_NUDGE_KM = {
    5: 2.5,
    6: 1.0,
    7: 0.4,
}

DIRECTIONS = ['north', 'south', 'east', 'west']


def parse_args():
    parser = argparse.ArgumentParser(
        description='Submit GEE batch exports for nudged H3 grids (sensitivity analysis)'
    )
    parser.add_argument('--resolution', '-r', type=int, default=6,
                        help='H3 resolution level (default: 6)')
    parser.add_argument('--direction', '-d', type=str,
                        choices=['north', 'south', 'east', 'west', 'all'],
                        default='all',
                        help='Nudge direction (default: all)')
    parser.add_argument('--nudge-km', type=float, default=None,
                        help='Nudge distance in km (default: resolution-specific)')
    parser.add_argument('--cities-per-task', type=int, default=50,
                        help='Number of cities per export task (default: 50, conservative)')
    parser.add_argument('--tile-scale', type=int, default=16,
                        help='GEE tileScale parameter for memory management (default: 16)')
    parser.add_argument('--max-tasks', type=int, default=None,
                        help='Maximum number of tasks to submit per direction')
    parser.add_argument('--dry-run', action='store_true',
                        help='Print what would be done without submitting')
    return parser.parse_args()


def initialize_gee():
    try:
        ee.Initialize(project=GEE_PROJECT)
        print(f"GEE initialized with project: {GEE_PROJECT}")
    except Exception:
        print("Authenticating with GEE...")
        ee.Authenticate()
        ee.Initialize(project=GEE_PROJECT)


def get_impervious_2015():
    year_of_first_ISA = [1972, 1978, 1985, 1986, 1987, 1988, 1989, 1990,
                         1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000,
                         2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,
                         2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]
    pixel_values = list(range(1, len(year_of_first_ISA) + 1))
    lookup_table = dict(zip(year_of_first_ISA, pixel_values))
    from_glc_image = ee.ImageCollection("projects/sat-io/open-datasets/GISA_1972_2019").mosaic()
    return from_glc_image.lte(lookup_table.get(2015))


def classify_pixels(building_height_img):
    building_type_img = ee.Image("JRC/GHSL/P2023A/GHS_BUILT_C/2018").select('built_characteristics')

    residential_mask = (
        building_type_img.eq(11).Or(building_type_img.eq(12))
        .Or(building_type_img.eq(13)).Or(building_type_img.eq(14)).Or(building_type_img.eq(15))
    )
    nonresidential_mask = (
        building_type_img.eq(21).Or(building_type_img.eq(22))
        .Or(building_type_img.eq(23)).Or(building_type_img.eq(24)).Or(building_type_img.eq(25))
    )

    lw_mask = building_height_img.lt(3)
    rs_mask = residential_mask.And(building_height_img.gte(3)).And(building_height_img.lt(12))
    rm_mask = residential_mask.And(building_height_img.gte(12)).And(building_height_img.lt(50))
    nr_mask = nonresidential_mask.And(building_height_img.gte(3)).And(building_height_img.lt(50))
    hr_mask = (residential_mask.Or(nonresidential_mask)).And(building_height_img.gte(50)).And(building_height_img.lte(100))

    return {'LW': lw_mask, 'RS': rs_mask, 'RM': rm_mask, 'NR': nr_mask, 'HR': hr_mask}


def create_esch2022_bands(impervious_2015):
    height = ee.Image("projects/ardent-spot-390007/assets/Esch2022_WSF3D/WSF3D_V02_BuildingHeight").multiply(0.1)
    footprint = ee.Image("projects/ardent-spot-390007/assets/Esch2022_WSF3D/WSF3D_V02_BuildingFraction").divide(100).multiply(90*90)
    volume = height.multiply(footprint)
    classes = classify_pixels(height)

    bands = []
    band_names = []
    for cls_name, mask in classes.items():
        band = volume.updateMask(mask).updateMask(impervious_2015).unmask(0).rename(f'vol_Esch2022_{cls_name}')
        bands.append(band)
        band_names.append(f'vol_Esch2022_{cls_name}')

    bands.append(footprint.updateMask(impervious_2015).unmask(0).rename('footprint_Esch2022'))
    band_names.append('footprint_Esch2022')

    return ee.Image.cat(bands), band_names, 90


def create_li2022_bands(impervious_2015):
    height = ee.Image("projects/ardent-spot-390007/assets/Li2022_Global3DBuiltup/height_mean")
    volume = ee.Image("projects/ardent-spot-390007/assets/Li2022_Global3DBuiltup/volume_mean").multiply(100000)
    footprint = ee.Image("projects/ardent-spot-390007/assets/Li2022_Global3DBuiltup/footprint_mean").multiply(1000*1000)
    classes = classify_pixels(height)

    bands = []
    band_names = []
    for cls_name, mask in classes.items():
        band = volume.updateMask(mask).updateMask(impervious_2015).unmask(0).rename(f'vol_Li2022_{cls_name}')
        bands.append(band)
        band_names.append(f'vol_Li2022_{cls_name}')

    bands.append(footprint.updateMask(impervious_2015).unmask(0).rename('footprint_Li2022'))
    band_names.append('footprint_Li2022')

    return ee.Image.cat(bands), band_names, 1000


def create_liu2024_bands(impervious_2015):
    volume = ee.Image("projects/ardent-spot-390007/assets/Liu2024_GlobalUrbanStructure_3D/GUS3D_Volume")
    height = ee.Image("projects/ardent-spot-390007/assets/Liu2024_GlobalUrbanStructure_3D/GUS3D_Height")
    footprint = volume.divide(height)
    classes = classify_pixels(height)

    bands = []
    band_names = []
    for cls_name, mask in classes.items():
        band = volume.updateMask(mask).updateMask(impervious_2015).unmask(0).rename(f'vol_Liu2024_{cls_name}')
        bands.append(band)
        band_names.append(f'vol_Liu2024_{cls_name}')

    bands.append(footprint.updateMask(impervious_2015).unmask(0).rename('footprint_Liu2024'))
    band_names.append('footprint_Liu2024')

    return ee.Image.cat(bands), band_names, 500


def create_other_bands(impervious_2015):
    population = ee.ImageCollection("WorldPop/GP/100m/pop").filterDate('2015-01-01', '2015-12-31').mosaic()
    pop_band = population.updateMask(impervious_2015).unmask(0).rename('population_2015')
    imp_band = impervious_2015.multiply(100).unmask(0).rename('impervious_2015')

    return ee.Image.cat([pop_band, imp_band]), ['population_2015', 'impervious_2015'], 100


def get_all_dataset_configs(impervious_2015):
    configs = []
    configs.append(('esch2022', *create_esch2022_bands(impervious_2015)))
    configs.append(('li2022', *create_li2022_bands(impervious_2015)))
    configs.append(('liu2024', *create_liu2024_bands(impervious_2015)))
    configs.append(('other', *create_other_bands(impervious_2015)))
    return configs


def load_nudged_h3_grids(resolution: int, direction: str, nudge_km: float) -> gpd.GeoDataFrame:
    """Load pre-generated nudged H3 grids."""
    nudged_dir = get_resolution_dir(PROCESSED_DIR, resolution) / "nudged"
    grids_file = nudged_dir / f"all_cities_h3_grids_resolution{resolution}_nudge_{direction}_{nudge_km}km.gpkg"

    if not grids_file.exists():
        raise FileNotFoundError(
            f"Nudged H3 grids file not found: {grids_file}\n"
            f"Run 01b_create_h3_grids_nudged.py --resolution {resolution} --direction {direction} first."
        )

    print(f"Loading nudged H3 grids from: {grids_file}")
    gdf = gpd.read_file(grids_file)
    print(f"Loaded {len(gdf)} H3 cells for direction={direction}")
    return gdf


def gdf_to_ee_fc(gdf: gpd.GeoDataFrame) -> ee.FeatureCollection:
    if 'h3index' not in gdf.columns:
        if gdf.index.name == 'h3index' or gdf.index.name == 'hex_id':
            gdf = gdf.reset_index()
            if 'hex_id' in gdf.columns:
                gdf = gdf.rename(columns={'hex_id': 'h3index'})

    geojson = json.loads(gdf[['h3index', 'geometry']].to_json())
    return ee.FeatureCollection(geojson)


def submit_export_task(fc_hex, image, task_name, description, scale, tile_scale=16, dry_run=False):
    stats = image.reduceRegions(
        collection=fc_hex,
        reducer=ee.Reducer.sum(),
        scale=scale,
        tileScale=tile_scale
    )

    if dry_run:
        print(f"  [DRY RUN] Would submit task: {task_name} (scale={scale}m, tileScale={tile_scale})")
        return {'task_id': None, 'name': task_name, 'status': 'dry_run', 'scale': scale, 'tileScale': tile_scale}

    task = ee.batch.Export.table.toDrive(
        collection=stats,
        description=task_name,
        folder=DRIVE_FOLDER,
        fileNamePrefix=task_name,
        fileFormat='CSV'
    )
    task.start()

    return {
        'task_id': task.id,
        'name': task_name,
        'description': description,
        'scale': scale,
        'tileScale': tile_scale,
        'status': 'SUBMITTED',
        'submitted_at': datetime.now().isoformat()
    }


def process_direction(
    direction: str,
    resolution: int,
    nudge_km: float,
    dataset_configs: list,
    cities_per_task: int,
    tile_scale: int,
    max_tasks: int,
    dry_run: bool,
    output_dir: Path
) -> List[Dict]:
    """Process a single nudge direction."""
    print(f"\n{'='*60}")
    print(f"Processing direction: {direction.upper()}")
    print(f"{'='*60}")

    # Load nudged grids
    try:
        h3_gdf = load_nudged_h3_grids(resolution, direction, nudge_km)
    except FileNotFoundError as e:
        print(f"ERROR: {e}")
        return []

    city_ids = h3_gdf['ID_HDC_G0'].unique()
    print(f"Total cities: {len(city_ids)}")

    # Split into batches
    n_batches = (len(city_ids) + cities_per_task - 1) // cities_per_task
    if max_tasks:
        n_batches = min(n_batches, max_tasks // len(dataset_configs))

    task_records = []
    today = datetime.now().strftime('%Y%m%d')

    for i in tqdm(range(n_batches), desc=f"Submitting {direction} batches"):
        start_idx = i * cities_per_task
        end_idx = min((i + 1) * cities_per_task, len(city_ids))
        batch_city_ids = city_ids[start_idx:end_idx]

        batch_h3 = h3_gdf[h3_gdf['ID_HDC_G0'].isin(batch_city_ids)]
        if len(batch_h3) == 0:
            continue

        fc_hex = gdf_to_ee_fc(batch_h3)

        for ds_name, ds_image, ds_bands, ds_scale in dataset_configs:
            task_name = f"nudge_{direction}_r{resolution}_{ds_name}_batch{i+1:04d}_{today}"
            description = f"{ds_name} - {direction} - Cities {start_idx+1}-{end_idx}"

            try:
                record = submit_export_task(
                    fc_hex=fc_hex,
                    image=ds_image,
                    task_name=task_name,
                    description=description,
                    scale=ds_scale,
                    tile_scale=tile_scale,
                    dry_run=dry_run
                )
                record['batch_num'] = i + 1
                record['dataset'] = ds_name
                record['direction'] = direction
                record['band_names'] = ds_bands
                record['city_ids'] = batch_city_ids.tolist()
                record['n_h3_cells'] = len(batch_h3)
                task_records.append(record)
            except Exception as e:
                print(f"  Error submitting {ds_name} batch {i+1}: {e}")
                task_records.append({
                    'batch_num': i + 1,
                    'dataset': ds_name,
                    'direction': direction,
                    'name': task_name,
                    'status': 'ERROR',
                    'error': str(e)
                })

    return task_records


def main():
    args = parse_args()
    resolution = args.resolution
    nudge_km = args.nudge_km or DEFAULT_NUDGE_KM.get(resolution, 1.0)

    directions = DIRECTIONS if args.direction == 'all' else [args.direction]

    print("=" * 70)
    print("GEE BATCH EXPORT - NUDGED H3 GRIDS (Sensitivity Analysis)")
    print("=" * 70)
    print(f"Resolution: {resolution}")
    print(f"Nudge distance: {nudge_km} km")
    print(f"Directions: {directions}")
    print(f"Cities per task: {args.cities_per_task}")
    print(f"Tile scale: {args.tile_scale}")
    print(f"Dry run: {args.dry_run}")
    print()

    initialize_gee()

    output_dir = get_resolution_dir(PROCESSED_DIR, resolution) / "nudged"
    output_dir.mkdir(parents=True, exist_ok=True)

    impervious_2015 = get_impervious_2015()
    dataset_configs = get_all_dataset_configs(impervious_2015)

    print("\nDatasets and scales:")
    for ds_name, _, ds_bands, ds_scale in dataset_configs:
        print(f"  {ds_name}: {len(ds_bands)} bands, scale={ds_scale}m")

    all_task_records = []

    for direction in directions:
        records = process_direction(
            direction=direction,
            resolution=resolution,
            nudge_km=nudge_km,
            dataset_configs=dataset_configs,
            cities_per_task=args.cities_per_task,
            tile_scale=args.tile_scale,
            max_tasks=args.max_tasks,
            dry_run=args.dry_run,
            output_dir=output_dir
        )
        all_task_records.extend(records)

    # Save manifest
    today = datetime.now().strftime('%Y%m%d')
    manifest_file = output_dir / f"batch_export_manifest_nudged_r{resolution}_{today}.json"

    manifest = {
        'resolution': resolution,
        'nudge_km': nudge_km,
        'directions': directions,
        'cities_per_task': args.cities_per_task,
        'tile_scale': args.tile_scale,
        'n_tasks': len(all_task_records),
        'datasets': [{'name': ds[0], 'bands': ds[2], 'scale': ds[3]} for ds in dataset_configs],
        'drive_folder': DRIVE_FOLDER,
        'submitted_at': datetime.now().isoformat(),
        'tasks': all_task_records
    }

    with open(manifest_file, 'w') as f:
        json.dump(manifest, f, indent=2, default=str)

    print(f"\n{'='*70}")
    print("SUBMISSION COMPLETE")
    print(f"{'='*70}")
    n_success = len([t for t in all_task_records if t.get('status') != 'ERROR'])
    print(f"Tasks submitted: {n_success}")
    print(f"Manifest saved to: {manifest_file}")
    print(f"\nExports will appear in Google Drive folder: {DRIVE_FOLDER}/")


if __name__ == "__main__":
    main()
